{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cfea62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pafy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.models import model_from_json \n",
    "from matplotlib import pyplot as plt\n",
    "import tkinter\n",
    "from tkinter import  *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b2f6447",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Loading the model\n",
    "model= model_from_json(open(\"./modeladam.json\",\"r\").read())\n",
    "model.load_weights('./modeladam.h5')\n",
    "\n",
    "emotions = ('angry','disgust','fear','happy','sad','surprise','neutral')\n",
    "\n",
    "face_cascade= cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')\n",
    "\n",
    "#Function for FED to work on front cam\n",
    "def fc():\n",
    "    #Starting the feed from the front cam\n",
    "    cap=cv2.VideoCapture(0)\n",
    "    while(True):\n",
    "        ret,img=cap.read()    \n",
    "        \n",
    "        #Converting the input stream to grayscale\n",
    "        gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #Detecting the faces from the grayscale stream\n",
    "        faces= face_cascade.detectMultiScale(gray,1.3,5)\n",
    "        \n",
    "        #Calssifying the expression on the face and tagging the expression near the face\n",
    "        for(x,y,w,h) in faces:\n",
    "            \n",
    "            #crop the face\n",
    "            face = img[int(y):int(y+h), int(x):int(x+w)]\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            #resize the face\n",
    "            face = cv2.resize(face, (48, 48))\n",
    "            \n",
    "            #Reshaping and Scaling\n",
    "            img_pixels=image.img_to_array(face)\n",
    "            img_pixels=np.expand_dims(img_pixels, axis=0)\n",
    "            img_pixels /=255\n",
    "            \n",
    "            #Detecting the expression in the face\n",
    "            predictions=model.predict(img_pixels)        \n",
    "            max_index = np.argmax(predictions[0])        \n",
    "            emotion=emotions[max_index]\n",
    "            \n",
    "            #Tagging the expression\n",
    "            cv2.putText(img,emotion,(int(x),int(y)),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2)\n",
    "        \n",
    "        #Showing the real time feed with the expression tagged along the face\n",
    "        cv2.imshow('img',img)\n",
    "        if (cv2.waitKey(10))==27:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "#Function for FED to work on youtube videos\n",
    "def yt():\n",
    "    #Getting the video's url\n",
    "    url=urlv.get()\n",
    "    video=pafy.new(url)\n",
    "    \n",
    "    #Getting the best video quality of the video\n",
    "    best=video.getbest(preftype=\"mp4\")\n",
    "    \n",
    "    #Streamming the video\n",
    "    cap=cv2.VideoCapture(best.url)\n",
    "    \n",
    "    while(True):\n",
    "        ret,img=cap.read()    \n",
    "        \n",
    "        #Converting the input stream to grayscale\n",
    "        gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #Detecting the faces from the grayscale stream\n",
    "        faces= face_cascade.detectMultiScale(gray,1.3,5)\n",
    "        \n",
    "        #Calssifying the expression on the face and tagging the expression near the face\n",
    "        for(x,y,w,h) in faces:\n",
    "            \n",
    "            #crop the face\n",
    "            face = img[int(y):int(y+h), int(x):int(x+w)]\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            #resize the face\n",
    "            face = cv2.resize(face, (48, 48))\n",
    "            \n",
    "            #Reshaping and resizing the face\n",
    "            img_pixels=image.img_to_array(face)\n",
    "            img_pixels=np.expand_dims(img_pixels, axis=0)\n",
    "            img_pixels /=255\n",
    "           \n",
    "            #Detecting the expression in the face\n",
    "            predictions=model.predict(img_pixels)        \n",
    "            max_index = np.argmax(predictions[0])        \n",
    "            emotion=emotions[max_index]\n",
    "            \n",
    "            #Tagging the expression\n",
    "            cv2.putText(img,emotion,(int(x),int(y)),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2)\n",
    "        \n",
    "        #Showing the real time feed with the expression tagged along the face\n",
    "        cv2.imshow('img',img)\n",
    "        if (cv2.waitKey(10))==27:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    urlv.set(\"\")\n",
    "\n",
    "#Function to for FED to work on pics    \n",
    "def localpic():\n",
    "    \n",
    "    #Getting the file path\n",
    "    filepath=lad.get()\n",
    "   \n",
    "    #Loading the image\n",
    "    img=image.load_img(filepath,grayscale=True,target_size=(48,48))\n",
    "    \n",
    "    #Preprocessing the image\n",
    "    x=image.img_to_array(img)\n",
    "    x=np.expand_dims(x,axis=0)\n",
    "    x=x/255\n",
    "    \n",
    "    #Detecting the expression\n",
    "    detect= model.predict(x)\n",
    "    \n",
    "    #Printing the graph of the various expression recorded from the image\n",
    "    y_pos = np.arange(len(emotions))    \n",
    "    plt.bar(y_pos, detect[0], align='center', alpha=0.5)\n",
    "    plt.xticks(y_pos, emotions)\n",
    "    plt.ylabel('percentage')\n",
    "    plt.title('emotion')    \n",
    "    plt.show()\n",
    "        \n",
    "    x = np.array(x, 'float32')\n",
    "    x = x.reshape([48, 48]);\n",
    "    \n",
    "    #Printing the image\n",
    "    plt.gray()\n",
    "    plt.imshow(x)   \n",
    "    plt.show()\n",
    "\n",
    "#Creating the UI\n",
    "master=tkinter.Tk()\n",
    "master.title(\"Facial Expression Detector\")\n",
    "master.geometry(\"600x600\")\n",
    "urlv=tkinter.StringVar()\n",
    "lad=tkinter.StringVar()\n",
    "\n",
    "lab=tkinter.Label(master,text=\"FED on Front Cam\", font = ('calibre',10,'normal'))\n",
    "lab.grid(row=0,column=3)\n",
    "button1=tkinter.Button(master, text=\"FED on front cam\", command=fc)\n",
    "button1.grid(row=1,column=3)\n",
    "\n",
    "lab1=tkinter.Label(master, text=\"FED on YOUTUBE (Enter the link of the video)\",font=('calibre',10, 'bold'))\n",
    "lab1.grid(row=2,column=3)\n",
    "ent1=tkinter.Entry(master, textvariable=urlv,font=('calibre',10, 'bold'))\n",
    "ent1.grid(row=3,column=3)\n",
    "button2=tkinter.Button(master, text=\"FED on Youtube\", command=yt)\n",
    "button2.grid(row=4,column=3)\n",
    "\n",
    "lab2=tkinter.Label(master, text=\"FED on image (Enter the path of the image saved locally)\",font=('calibre',10, 'bold'))\n",
    "lab2.grid(row=5,column=3)\n",
    "ent2=tkinter.Entry(master, textvariable=lad,font=('calibre',10, 'bold'))\n",
    "ent2.grid(row=6,column=3)\n",
    "button3=tkinter.Button(master, text=\"FED on image\", command=localpic)\n",
    "button3.grid(row=7,column=3)\n",
    "\n",
    "master.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
